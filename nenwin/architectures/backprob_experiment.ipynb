{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f50bd5474255f82aa829301912ce59e29110123be660cf8d7583f66a20371684"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Nenwin-project (NEural Networks WIthout Neurons) for\n",
    "the AI Honors Academy track 2020-2021 at the TU Eindhoven.\n",
    "\n",
    "Author: Lulof Pirée\n",
    "March 2021\n",
    "\n",
    "Copyright (C) 2020 Lulof Pirée, \n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU Affero General Public License as published\n",
    "by the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU Affero General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU Affero General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Backprob experiment\n",
    "\n",
    "This file provides a full run of backpropagating though an entire `NenwinModel`.\n",
    "\n",
    "Author: Lulof Pirée"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchviz\n",
    "\n",
    "from nenwin.all_particles import Marble, Node, MarbleEaterNode, MarbleEmitterNode\n",
    "from nenwin.model import NenwinModel\n",
    "from nenwin.attraction_functions.attraction_functions import NewtonianGravity"
   ]
  },
  {
   "source": [
    "## Approach\n",
    "\n",
    "1. Decide how to capture output and network architecture.\n",
    "1. Set up the model and the particles.\n",
    "1. Add a loss function.\n",
    "1. Visualize the model.\n",
    "1. Run the model.\n",
    "1. Backpropagate and update.\n",
    "1. Compare differences in model.\n",
    "\n",
    "### Design\n",
    "Let's create a ring of Nodes, say 5 of them, and put one Marble in there. Not in the center, just somewhere within the circle of space (let's keep it 2D) enclosed by the ring of Nodes.\n",
    "Now let the loss simply be the distance of the Marble to the center of the circle **after 5 seconds from the start**.\n",
    "\n",
    "One likely result -- if everything works -- is that the Marble simply is placed stationary on this position. But that would already be some successfull optimization!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "zero = torch.tensor([0, 0], dtype=torch.float)\n",
    "mass = 10\n",
    "\n",
    "center = torch.tensor([0, 0], dtype=torch.float, requires_grad=False)\n",
    "node_positions = [torch.tensor(pos, dtype=torch.float) for pos in ((0, 10), (10, 0), (0, -10), (-10, 0))]\n",
    "marble_pos = torch.tensor([2, 2], dtype=torch.float)\n",
    "\n",
    "nodes = [Node(pos, zero, zero, mass, NewtonianGravity(), 1, 1, 1, 1) \n",
    "    for pos in node_positions]\n",
    "\n",
    "marble = Marble(marble_pos, zero, zero, mass, NewtonianGravity(), None)\n",
    "\n",
    "model = NenwinModel(nodes, (marble,))\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.RMSprop(model.parameters())\n",
    "\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "step_size = 5\n",
    "\n",
    "for epoch in range(25):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    marble.zero_grad(set_to_none=True)\n",
    "\n",
    "\n",
    "    model.reset()\n",
    "    \n",
    "    \n",
    "    t = 0\n",
    "    while t <= 5:\n",
    "        model.make_timestep(step_size)\n",
    "        t += step_size\n",
    "\n",
    "    loss = torch.mean(torch.pow(marble.pos - torch.tensor([0, 0], dtype=torch.float), 2))\n",
    "    print(f\"epoch {epoch}, loss:\", loss.item())\n",
    "\n",
    "    loss.backward(retain_graph=False)\n",
    "    optimizer.step()\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0, loss: 75.67821502685547\n",
      "epoch 1, loss: 7075.68359375\n",
      "epoch 2, loss: 407.37286376953125\n",
      "epoch 3, loss: 575.3104248046875\n",
      "epoch 4, loss: 44.499061584472656\n",
      "epoch 5, loss: 12.239363670349121\n",
      "epoch 6, loss: 2.234576463699341\n",
      "epoch 7, loss: 0.8070439100265503\n",
      "epoch 8, loss: 0.3302481174468994\n",
      "epoch 9, loss: 0.17212143540382385\n",
      "epoch 10, loss: 0.0909072756767273\n",
      "epoch 11, loss: 0.05146942660212517\n",
      "epoch 12, loss: 0.029325084760785103\n",
      "epoch 13, loss: 0.017368178814649582\n",
      "epoch 14, loss: 0.010421965271234512\n",
      "epoch 15, loss: 0.006448574364185333\n",
      "epoch 16, loss: 0.004057787358760834\n",
      "epoch 17, loss: 0.002623380860313773\n",
      "epoch 18, loss: 0.00172851060051471\n",
      "epoch 19, loss: 0.0011680437019094825\n",
      "epoch 20, loss: 0.0008054352947510779\n",
      "epoch 21, loss: 0.0005689528188668191\n",
      "epoch 22, loss: 0.00041007850086316466\n",
      "epoch 23, loss: 0.00030227468232624233\n",
      "epoch 24, loss: 0.00022752095537725836\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.0202,  0.0067], grad_fn=<CloneBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "marble.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Node(tensor([-0.0880, 10.0888]),tensor([-0.0887,  0.0705]),tensor([-0.0899,  0.0621]),9.953563690185547,NewtonianGravity(),0.83430415391922,0.8788398504257202,0.9637365937232971,0.9045029282569885)\nNode(tensor([10.0854, -0.0761]),tensor([ 0.0731, -0.0790]),tensor([ 0.0586, -0.0824]),9.968395233154297,NewtonianGravity(),0.8999937176704407,0.899973452091217,0.9819895625114441,0.8725152015686035)\nNode(tensor([ 8.1299e-03, -1.0051e+01]),tensor([-0.0080, -0.0510]),tensor([-0.0349, -0.0472]),10.161704063415527,NewtonianGravity(),0.8879862427711487,0.8107105493545532,1.1657471656799316,0.8995038270950317)\nNode(tensor([-10.0183,   0.0135]),tensor([-0.0162,  0.0041]),tensor([-0.0113, -0.0100]),10.182886123657227,NewtonianGravity(),1.000003695487976,0.9989473819732666,1.1838268041610718,1.2057993412017822)\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"marble_to_middle.p\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "file = open(\"marble_to_middle.p\", \"rb\")\n",
    "model = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from nenwin.architectures.run_and_visualize import run\n",
    "\n",
    "model.reset()\n",
    "run(model.marbles, model.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del run"
   ]
  },
  {
   "source": [
    "## Try it with a single Marble -- do the same errors happen?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "end epoch 0\n",
      "0\n",
      "0\n",
      "0\n",
      "end epoch 1\n",
      "1\n",
      "0\n",
      "1\n",
      "end epoch 2\n",
      "2\n",
      "0\n",
      "2\n",
      "end epoch 3\n",
      "3\n",
      "0\n",
      "3\n",
      "end epoch 4\n",
      "4\n",
      "0\n",
      "4\n",
      "end epoch 5\n",
      "5\n",
      "0\n",
      "5\n",
      "end epoch 6\n",
      "6\n",
      "0\n",
      "6\n",
      "end epoch 7\n",
      "7\n",
      "0\n",
      "7\n",
      "end epoch 8\n",
      "8\n",
      "0\n",
      "8\n",
      "end epoch 9\n",
      "9\n",
      "0\n",
      "9\n",
      "end epoch 10\n",
      "10\n",
      "0\n",
      "10\n",
      "end epoch 11\n",
      "11\n",
      "0\n",
      "11\n",
      "end epoch 12\n",
      "12\n",
      "0\n",
      "12\n",
      "end epoch 13\n",
      "13\n",
      "0\n",
      "13\n",
      "end epoch 14\n",
      "14\n",
      "0\n",
      "14\n",
      "end epoch 15\n",
      "15\n",
      "0\n",
      "15\n",
      "end epoch 16\n",
      "16\n",
      "0\n",
      "16\n",
      "end epoch 17\n",
      "17\n",
      "0\n",
      "17\n",
      "end epoch 18\n",
      "18\n",
      "0\n",
      "18\n",
      "end epoch 19\n",
      "19\n",
      "0\n",
      "19\n",
      "end epoch 20\n",
      "20\n",
      "0\n",
      "20\n",
      "end epoch 21\n",
      "21\n",
      "0\n",
      "21\n",
      "end epoch 22\n",
      "22\n",
      "0\n",
      "22\n",
      "end epoch 23\n",
      "23\n",
      "0\n",
      "23\n",
      "end epoch 24\n",
      "24\n",
      "0\n",
      "24\n",
      "prev_prev: 0\n",
      "prev: 0\n",
      "init: 25\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f68acace6d0>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.46.1 (0)\n -->\n<!-- Pages: 1 -->\n<svg width=\"203pt\" height=\"99pt\"\n viewBox=\"0.00 0.00 203.00 99.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 95)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-95 199,-95 199,4 -4,4\"/>\n<!-- 140087550338896 -->\n<g id=\"node1\" class=\"node\">\n<title>140087550338896</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"154,-21 41,-21 41,0 154,0 154,-21\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">CloneBackward</text>\n</g>\n<!-- 140087550338960 -->\n<g id=\"node2\" class=\"node\">\n<title>140087550338960</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"195,-91 0,-91 0,-57 195,-57 195,-91\"/>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-77.4\" font-family=\"Times,serif\" font-size=\"12.00\">_InitialValueParticle__init_acc</text>\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (2)</text>\n</g>\n<!-- 140087550338960&#45;&gt;140087550338896 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140087550338960&#45;&gt;140087550338896</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97.5,-56.84C97.5,-49.01 97.5,-39.54 97.5,-31.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"101,-31.04 97.5,-21.04 94,-31.04 101,-31.04\"/>\n</g>\n</g>\n</svg>\n"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "marble = Marble(marble_pos, zero, zero, mass, NewtonianGravity(), None)\n",
    "optimizer = torch.optim.Adam(marble.parameters())\n",
    "step_time=0.5\n",
    "\n",
    "\n",
    "for epoch in range(25):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    marble.zero_grad(set_to_none=True)\n",
    "    marble.reset()\n",
    "    # print(vars(marble))\n",
    "    t = 0\n",
    "    while t <= 5:\n",
    "        marble.update_movement(time_passed=step_time)\n",
    "        t += step_size\n",
    "\n",
    "    loss = torch.mean(torch.pow(marble.pos - torch.tensor([0, 0], dtype=torch.float), 2))\n",
    "\n",
    "    print(f\"end epoch {epoch}\")\n",
    "    print(marble.init_pos._version)\n",
    "    print(marble._PhysicalParticle__mass._version)\n",
    "    print(marble._InitialValueParticle__init_pos._version)\n",
    "\n",
    "    try:\n",
    "        loss.backward()\n",
    "        del loss\n",
    "        optimizer.step()\n",
    "    except:\n",
    "        print(\"Error occured\")\n",
    "        break\n",
    "print(\"prev_prev:\", marble._prev_prev_acc._version)\n",
    "print(\"prev:\", marble._prev_acc._version)\n",
    "print(\"init:\", marble.init_acc._version)\n",
    "torchviz.make_dot(marble._prev_acc, params=dict(marble.named_parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on function make_dot in module torchviz.dot:\n\nmake_dot(var, params=None)\n    Produces Graphviz representation of PyTorch autograd graph.\n    \n    Blue nodes are the Variables that require grad, orange are Tensors\n    saved for backward in torch.autograd.Function\n    \n    Args:\n        var: output Variable\n        params: dict of (name, Variable) to add names to node that\n            require grad (TODO: make optional)\n\n"
     ]
    }
   ],
   "source": [
    "help(torchviz.make_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "a = torch.tensor([1.0], requires_grad = True)\n",
    "a[0] += 1\n",
    "a._version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "b = a.clone()\n",
    "b._version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.my_param = nn.Parameter(torch.tensor([1.0], requires_grad=True))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self.my_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n0\n0\n"
     ]
    }
   ],
   "source": [
    "mm = MyModule()\n",
    "optim = torch.optim.Adam(mm.parameters())\n",
    "\n",
    "for epoch in range(2):\n",
    "    optim.zero_grad()\n",
    "    loss = mm(torch.tensor([2.0]))\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "print(mm.my_param._version)\n",
    "print(mm(torch.tensor([2.0]))._version)\n",
    "print(loss._version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}