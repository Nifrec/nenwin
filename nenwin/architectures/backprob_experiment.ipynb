{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f50bd5474255f82aa829301912ce59e29110123be660cf8d7583f66a20371684"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Nenwin-project (NEural Networks WIthout Neurons) for\n",
    "the AI Honors Academy track 2020-2021 at the TU Eindhoven.\n",
    "\n",
    "Author: Lulof Pirée\n",
    "March 2021\n",
    "\n",
    "Copyright (C) 2020 Lulof Pirée, Teun Schilperoort\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU Affero General Public License as published\n",
    "by the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU Affero General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU Affero General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Backprob experiment\n",
    "\n",
    "This file provides a full run of backpropagating though an entire `NenwinModel`.\n",
    "\n",
    "Author: Lulof Pirée"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchviz\n",
    "\n",
    "from nenwin.all_particles import Marble, Node, MarbleEaterNode, MarbleEmitterNode\n",
    "from nenwin.model import NenwinModel\n",
    "from nenwin.attraction_functions.attraction_functions import NewtonianGravity"
   ]
  },
  {
   "source": [
    "## Approach\n",
    "\n",
    "1. Decide how to capture output and network architecture.\n",
    "1. Set up the model and the particles.\n",
    "1. Add a loss function.\n",
    "1. Visualize the model.\n",
    "1. Run the model.\n",
    "1. Backpropagate and update.\n",
    "1. Compare differences in model.\n",
    "\n",
    "### Design\n",
    "Let's create a ring of Nodes, say 5 of them, and put one Marble in there. Not in the center, just somewhere within the circle of space (let's keep it 2D) enclosed by the ring of Nodes.\n",
    "Now let the loss simply be the distance of the Marble to the center of the circle **after 5 seconds from the start**.\n",
    "\n",
    "One likely result -- if everything works -- is that the Marble simply is placed stationary on this position. But that would already be some successfull optimization!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "zero = torch.tensor([0, 0], dtype=torch.float)\n",
    "mass = 10\n",
    "\n",
    "center = torch.tensor([0, 0], dtype=torch.float, requires_grad=False)\n",
    "node_positions = [torch.tensor(pos, dtype=torch.float) for pos in ((0, 10), (10, 0), (0, -10), (-10, 0))]\n",
    "marble_pos = torch.tensor([2, 2], dtype=torch.float)\n",
    "\n",
    "nodes = [Node(pos, zero, zero, mass, NewtonianGravity(), 1, 1, 1, 1) \n",
    "    for pos in node_positions]\n",
    "\n",
    "marble = Marble(marble_pos, zero, zero, mass, NewtonianGravity(), None)\n",
    "\n",
    "model = NenwinModel(nodes, (marble,))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "step_size = 5\n",
    "\n",
    "for epoch in range(25):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    marble.zero_grad(set_to_none=True)\n",
    "    print(f\"Before reset epoch {epoch}\")\n",
    "    print(marble.init_pos._version)\n",
    "\n",
    "\n",
    "    # model.reset()\n",
    "    marble.zero_grad(set_to_none=True)\n",
    "    marble.reset()\n",
    "    \n",
    "    for node in nodes:\n",
    "        node.reset()\n",
    "        node.zero_grad(set_to_none=True)\n",
    "    \n",
    "    print(f\"being epoch {epoch}\")\n",
    "    print(marble.init_pos._version)\n",
    "    \n",
    "    t = 0\n",
    "    while t <= 5:\n",
    "        model.make_timestep(step_size)\n",
    "        t += step_size\n",
    "\n",
    "    # loss = torch.abs(marble.pos[0]) #+ torch.abs(marble.pos[1])\n",
    "    # loss = torch.mean(torch.pow(marble.pos - torch.tensor([0, 0], dtype=torch.float), 2))\n",
    "    # print(loss)\n",
    "\n",
    "    print(f\"end epoch {epoch}\")\n",
    "    print(marble.init_pos._version)\n",
    "    marble.pos[0].backward()\n",
    "    # loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before reset epoch 0\n",
      "0\n",
      "being epoch 0\n",
      "0\n",
      "end epoch 0\n",
      "0\n",
      "Before reset epoch 1\n",
      "1\n",
      "being epoch 1\n",
      "1\n",
      "end epoch 1\n",
      "1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []] is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-bcad25491017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"end epoch {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mmarble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;31m# loss.backward(retain_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []] is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(('140508858068816._InitialValueParticle__init_pos',\n",
       "  Parameter containing:\n",
       "  tensor([1.9990, 1.9990], requires_grad=True)),\n",
       " ('140508858068816._InitialValueParticle__init_vel',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0010, -0.0010], requires_grad=True)),\n",
       " ('140508858068816._InitialValueParticle__init_acc',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0010, -0.0010], requires_grad=True)),\n",
       " ('140508858068816._PhysicalParticle__mass',\n",
       "  Parameter containing:\n",
       "  tensor(10.0010, requires_grad=True)),\n",
       " ('140508858068816._Node__marble_stiffness',\n",
       "  Parameter containing:\n",
       "  tensor(1., requires_grad=True)),\n",
       " ('140508858068816._Node__node_stiffness',\n",
       "  Parameter containing:\n",
       "  tensor(0.0010, requires_grad=True)),\n",
       " ('140508858068816._Node__marble_attraction',\n",
       "  Parameter containing:\n",
       "  tensor(0., requires_grad=True)),\n",
       " ('140508858068816._Node__node_attraction',\n",
       "  Parameter containing:\n",
       "  tensor(1., requires_grad=True)))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model = NenwinModel([], (marble,))\n",
    "tuple(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2., 2.], grad_fn=<CloneBackward>) tensor([0., 0.], grad_fn=<CloneBackward>) tensor([0., 0.], grad_fn=<CloneBackward>) Parameter containing:\ntensor(10., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(marble.pos, marble.vel, marble.acc, marble.mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "dir(marble.pos)\n",
    "print(marble.pos._version)"
   ]
  },
  {
   "source": [
    "## Try it with a single Marble -- do the same errors happen?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "being epoch 0\n",
      "0\n",
      "end epoch 0\n",
      "0\n",
      "being epoch 1\n",
      "0\n",
      "end epoch 1\n",
      "0\n",
      "being epoch 2\n",
      "0\n",
      "end epoch 2\n",
      "0\n",
      "being epoch 3\n",
      "0\n",
      "end epoch 3\n",
      "0\n",
      "being epoch 4\n",
      "0\n",
      "end epoch 4\n",
      "0\n",
      "being epoch 5\n",
      "0\n",
      "end epoch 5\n",
      "0\n",
      "being epoch 6\n",
      "0\n",
      "end epoch 6\n",
      "0\n",
      "being epoch 7\n",
      "0\n",
      "end epoch 7\n",
      "0\n",
      "being epoch 8\n",
      "0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-c45549f136e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_timestep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Vault/Documents/bachelor_3/honors/nenwin/nenwin/model.py\u001b[0m in \u001b[0;36mmake_timestep\u001b[0;34m(self, time_passed)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__all_particles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_movement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_passed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmarble\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__marbles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Vault/Documents/bachelor_3/honors/nenwin/nenwin/particle.py\u001b[0m in \u001b[0;36mupdate_movement\u001b[0;34m(self, time_passed)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m    140\u001b[0m         self.pos = self.pos + time_passed * self.vel + (1/6)*(time_passed**2)*(\n\u001b[0;32m--> 141\u001b[0;31m             4*self._prev_acc - self._prev_prev_acc)\n\u001b[0m\u001b[1;32m    142\u001b[0m         self.vel = self.vel + (1/12)*time_passed*(\n\u001b[1;32m    143\u001b[0m             5*self.acc + 8*self._prev_acc - self._prev_prev_acc)\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mformat_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "marble = Marble(marble_pos, zero, zero, mass, NewtonianGravity(), None)\n",
    "\n",
    "for epoch in range(25):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    marble.zero_grad(set_to_none=True)\n",
    "    marble.reset()\n",
    "    \n",
    "    print(f\"being epoch {epoch}\")\n",
    "    print(marble.init_pos._version)\n",
    "    \n",
    "    t = 0\n",
    "    while t <= 5:\n",
    "        model.make_timestep(step_size)\n",
    "        t += step_size\n",
    "\n",
    "    loss = torch.mean(torch.pow(marble.pos - torch.tensor([0, 0], dtype=torch.float), 2))\n",
    "    # print(loss)\n",
    "\n",
    "    print(f\"end epoch {epoch}\")\n",
    "    print(marble.init_pos._version)\n",
    "\n",
    "    marble.pos[0].backward(retain_graph=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}